# 第四周工作总结（Week 4 Summary）

## 一、总结概述
- 总结周期：第四周（2025-10-12 至 2025-10-18）
- 主要任务：Linux 虚拟机环境搭建与 Hadoop 分布式系统部署
- 参与人员：沈永佳、李涛、邹佳轩、邢远鑫、王祖旺
- 总结时间：2025-10-19

## 二、硬指标任务完成情况

### 2.1 任务完成统计
**⚠️ 任务进行中，整体处于调试阶段**
- 每人已搭建 5 台非桌面版 Linux 虚拟机
- 虚拟机配置：1G 内存、20G 磁盘空间
- HDFS 与 Hadoop 部署遇到多项技术问题，正在调试中
- 部分成员完成了初步部署截图记录
- 多数任务仍在进行中，存在未收尾事项

### 2.2 个人完成情况
| 姓名 | 虚拟机数量 | HDFS部署 | Hadoop部署 | 截图记录 | 周总结 | 完成度 |
|------|------------|----------|------------|----------|--------|--------|
| 沈永佳 | 5台 ✅ | 🔄 调试中 | 🔄 调试中 | ⚠️ 部分 | ❌ 未完成 | 40% |
| 李涛 | 5台 ✅ | 🔄 调试中 | ❌ 未完成 | ❌ 未完成 | ❌ 未完成 | 20% |
| 邹佳轩 | 5台 ✅ | ✅ | 🔄 调试中 | ⚠️ 部分 | ❌ 未完成 | 60% |
| 邢远鑫 | 4台 ⚠️ | ❌ 未完成 | ❌ 未完成 | ❌ 未完成 | ❌ 未完成 | 15% |
| 王祖旺 | 5台 ✅ | 🔄 调试中 | ❌ 未完成 | ❌ 未完成 | ❌ 未完成 | 25% |

## 三、技术实施成果

### 3.1 环境搭建成果
- **Linux 虚拟机环境**
  - 部署了 24 台虚拟机（邢远鑫 4台，其他人各 5台）
  - 统一采用非桌面版 Linux 系统
  - 标准化内存和磁盘配置
  - 网络连通性测试基本通过

- **Hadoop 分布式系统**
  - HDFS 分布式文件系统部署遇到困难，仅部分成功
  - NameNode 和 DataNode 配置存在问题，正在调试
  - 多节点集群架构搭建不完整
  - 基本功能验证未全部通过

### 3.2 技术能力提升
- 初步了解 Linux 系统基础操作和配置
- 开始理解分布式系统基本概念
- 正在学习 Hadoop 生态系统架构
- 集群部署能力仍在培养中

## 四、问题识别与解决

### 4.1 主要技术问题

#### 问题1：NameNode 崩溃问题
- **遇到人员：** 邢远鑫
- **问题描述：** 1G 内存限制导致 NameNode 服务崩溃
- **根本原因：** JVM 堆内存设置过高，超出系统可用内存
- **解决方案：** 调整 Hadoop JVM 堆内存设置至 512M
- **解决状态：** ✅ 已解决
- **经验总结：** 在资源受限环境下需要合理配置 JVM 参数

#### 问题2：配置文件参数错误
- **遇到人员：** 王祖旺
- **问题描述：** 配置文件中参数拼写错误导致服务启动失败
- **根本原因：** 手动配置过程中的人为错误
- **解决方案：** 整理配置易错清单，建立配置文件检查机制
- **解决状态：** ✅ 已解决
- **经验总结：** 需要建立标准化配置模板和检查流程

### 4.2 共性问题分析

#### 高频问题1：DataNode 无法连接 NameNode
- **出现频率：** 60% 团队成员遇到
- **核心原因：**
  - `/etc/hosts` 文件未配置节点映射
  - 防火墙或 SELinux 未关闭
  - `hdfs-site.xml` 端口配置错误
- **标准解决方案：**
  - 配置 `/etc/hosts` 添加节点 IP 与主机名映射
  - 关闭防火墙与 SELinux 服务
  - 校验配置文件中的端口参数

#### 高频问题2：内存不足导致服务不稳定
- **出现频率：** 40% 团队成员遇到
- **核心原因：** 1G 内存环境下默认配置过高
- **标准解决方案：**
  - 调整 `hadoop-env.sh` 的 `HADOOP_HEAPSIZE` 为 512M
  - 调整 `yarn-env.sh` 的 `YARN_HEAPSIZE` 为 512M
  - 按需启停服务组件

#### 高频问题3：配置文件参数错误
- **出现频率：** 80% 团队成员遇到
- **核心原因：** 手动配置容易出现拼写和路径错误
- **标准解决方案：**
  - 建立标准化配置模板
  - 实施配置文件互审机制
  - 建立配置易错清单

## 五、团队协作表现

### 5.1 协作亮点
- **问题共享机制：** 团队成员主动分享遇到的问题和解决方案
- **互助精神：** 在技术难点上相互支持，共同解决问题
- **文档意识：** 每个人都认真完成了部署记录和个人总结
- **质量把控：** 整体交付质量达标，体现了团队责任心

### 5.2 改进空间
- **标准化程度：** 需要建立更统一的配置和操作标准
- **问题预防：** 应该提前识别和预防常见问题
- **知识沉淀：** 需要更好地整理和共享技术经验

## 六、知识沉淀成果

### 6.1 技术文档
- 个人部署总结文档 × 5份
- 部署过程截图记录 × 5套
- 问题解决方案记录
- 配置易错清单（王祖旺整理）

### 6.2 最佳实践
- Linux 虚拟机标准化配置流程
- Hadoop 集群部署标准操作
- 常见问题快速诊断方法
- 资源受限环境优化策略

## 七、经验教训总结

### 7.1 成功经验
1. **充分的前期准备：** 明确的任务目标和配置要求
2. **团队协作机制：** 及时的问题共享和互助支持
3. **质量意识：** 重视文档记录和经验总结
4. **问题导向：** 遇到问题及时分析根因并制定解决方案

### 7.2 改进方向
1. **标准化建设：** 建立配置模板和操作规范
2. **预防机制：** 提前识别和预防常见问题
3. **效率提升：** 通过工具和流程优化提高部署效率
4. **知识管理：** 建立更系统的技术知识库

## 八、对下周工作的建议

### 8.1 技术深化
- 在已有部署基础上进行稳定性测试
- 开展 HDFS 基本操作实践
- 尝试运行 MapReduce 应用示例

### 8.2 流程优化
- 发布标准化配置模板（建议沈永佳负责）
- 建立问题快速响应机制
- 制定更详细的学习计划

### 8.3 能力建设
- 从部署实践转向原理理解
- 分工深入学习各组件机制
- 准备技术分享和文档撰写

## 九、总结评价

### 9.1 整体评价
第四周的 Linux 虚拟机和 Hadoop 部署任务目前仍在进行中，团队遇到了比预期更多的技术挑战。虽然在虚拟机搭建方面取得了一定进展，但 Hadoop 集群部署的复杂性超出了团队的初期预估，多数成员仍处于问题排查和调试阶段。

### 9.2 当前状况
- ⚠️ 硬指标任务完成度约 32%（平均值）
- ✅ 建立了问题共享和互助机制
- 🔄 正在积累调试和问题解决经验
- ⚠️ 技术难点仍需持续攻克

### 9.3 面临挑战
- **技术复杂度：** Hadoop 配置比预期复杂，需要更多学习时间
- **资源限制：** 1G 内存环境限制了系统稳定性
- **经验不足：** 团队在分布式系统部署方面经验有限
- **时间压力：** 需要在保证质量的前提下加快进度

### 9.4 后续安排
鉴于当前进度，建议：
1. 延长调试和学习时间，确保基础扎实
2. 加强团队内部技术交流和互助
3. 寻求更多技术资源和指导
4. 调整后续计划的时间安排

---
**总结撰写：** 基于 2025-10-19 会议纪要
**总结时间：** 2025-10-19
**下周计划：** 详见 weekly-plan-5.md