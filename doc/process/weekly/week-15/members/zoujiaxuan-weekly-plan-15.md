# 邹佳轩第 15 周学习计划

第 15 周（2025-12-29 至 2026-01-04）

## 本周学习目标

1.  **本地 LLM 环境部署**：搭建私有化大模型推理环境，摆脱对公网 API 的依赖。
2.  **AI 诊断接口开发**：基于 FastAPI 开发故障诊断服务，实现 Prompt 工程化。
3.  **RAG 技术探索**：引入检索增强生成技术，利用项目文档提升 AI 诊断的准确性。

## 详细学习任务

### 1. 模型选型与部署
- [ ] 调研开源大模型（Qwen2.5, Llama3），选择适合本地显存（<16GB）的版本。
- [ ] 使用 Ollama 或 vLLM 部署推理服务，并开启兼容 OpenAI 的 API 接口。
- [ ] 测试不同量化精度（4bit vs 8bit）下的推理速度与生成质量。

### 2. AI 业务逻辑开发
- [ ] 设计针对 Hadoop 故障诊断的 System Prompt，规范输出格式。
- [ ] 开发后端接口，实现“接收日志 -> 组装 Prompt -> 调用 LLM -> 流式返回”的完整链路。
- [ ] 优化前端交互，支持 SSE（Server-Sent Events）打字机效果。

### 3. 知识库增强 (RAG)
- [ ] 收集 Hadoop 官方文档与历史故障案例，进行文本清洗与分块。
- [ ] 使用 Embedding 模型将文本向量化，并存入 ChromaDB 向量数据库。
- [ ] 实现“检索 + 生成”流程，将相关知识作为上下文注入 Prompt。

## 预估产出物

1.  本地 LLM 启动脚本与性能测试报告。
2.  集成了 AI 诊断功能的后端代码模块。
3.  典型故障诊断案例演示视频。

## 重点难点分析

- **难点**：Prompt 的调优（Prompt Engineering），如何让模型准确输出结构化建议而非闲聊。
- **对策**：建立 Prompt 版本库，通过大量真实日志样本进行迭代测试。

---

**计划人**：邹佳轩
**制定时间**：第 15 周初
