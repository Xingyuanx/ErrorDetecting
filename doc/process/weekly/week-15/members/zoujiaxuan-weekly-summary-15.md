# 邹佳轩第 15 周学习总结

第 15 周（2025-12-29 至 2026-01-04）

## 本周完成情况概览

### 已完成内容

1.  **本地 LLM 环境部署（12/29）**
    - 使用 Ollama 部署 Qwen2.5-Coder 与 Llama3 模型
    - 搭建 vLLM 推理服务，提供兼容 OpenAI 格式的 API 接口
    - 对比不同量化版本（4bit/8bit）在本地显存下的推理速度与效果
    - 交付物：本地 LLM 启动脚本与性能测试报告

2.  **AI Agent 接口开发（12/30）**
    - 基于 FastAPI 封装 AI 诊断服务，对接 vLLM 接口
    - 设计 Prompt 模板，包含“角色设定+上下文（日志）+任务指令+输出格式”
    - 实现流式输出（SSE），提升前端用户体验
    - 涉及文件：`backend/app/routers/ai.py`、`backend/app/services/llm.py`

3.  **故障诊断功能初步跑通（01/01）**
    - 联调“日志采集 -> 存入数据库 -> 读取日志 -> 发送给 AI -> 返回诊断”全链路
    - 针对 Hadoop 常见报错（如 DataNode 丢失、SafeMode）优化 Prompt
    - 验证 AI 给出的修复建议准确性，并进行人工微调
    - 交付物：故障诊断演示视频、典型案例 Prompt 库

4.  **RAG（检索增强生成）探索（01/02）**
    - 尝试将 Hadoop 官方文档与过往故障知识库向量化（使用 ChromaDB）
    - 在诊断流程中引入知识库检索，减少模型幻觉
    - 验证发现 RAG 能显著提升对特定版本配置参数建议的准确度

### 部分完成/待完善内容

1.  Agent 目前仅能给出建议，尚未实现“自动执行修复命令”的功能（需 MCP 支持）
2.  多轮对话上下文管理尚简陋，长对话可能丢失早期信息
3.  推理延迟在并发请求下较高，需设计请求队列或限流机制

### 各领域掌握程度评估

#### 大模型应用开发（LLM Ops）

- 掌握状态：熟悉 Prompt 工程与本地模型部署接口
- 具体表现：成功将通用大模型转化为特定领域的故障诊断助手
- 能力描述：具备开发基于 LLM 的垂直应用的能力

#### AI 后端集成

- 掌握状态：掌握 SSE 流式传输与异步推理调用
- 具体表现：实现了低延迟的 AI 交互接口
- 能力描述：能够解决 AI 模型高延迟与 Web 实时交互之间的矛盾

## 问题分析与反思

### 主要收益

1.  项目核心亮点“AI 故障诊断”终于落地，形成了差异化竞争力
2.  深刻体会了 Prompt Quality 对输出结果的决定性影响
3.  掌握了本地部署大模型的低成本方案，摆脱了对昂贵商业 API 的依赖

### 存在不足与改进方向

1.  模型对长日志（超过 Context Window）的处理仍需截断，可能丢失关键信息
2.  缺乏对 AI 输出结果的自动评估机制（Eval），依赖人工主观判断
3.  知识库构建尚未自动化，文档更新滞后

## 下周重点与计划

1.  进行全系统集成测试，模拟从 Hadoop 故障发生到 AI 给出诊断的完整闭环
2.  配合前端优化 AI 对话界面，支持 Markdown 渲染与代码高亮
3.  整理项目文档，准备最终验收答辩材料
4.  编写系统部署手册，确保在全新环境下可一键复现

## 总体评价与展望

本周实现了 AI 技术的赋能，将项目的技术含量提升了一个台阶。虽然目前的 Agent 还比较初级，但已经展现出了强大的辅助运维潜力。下周将进入最后的冲刺阶段，聚焦于系统的整体打磨与交付。

---

**总结人**：邹佳轩
**总结时间**：第 15 周末
