# 第十周组周计划（Week 10）

## 目标概述
- 完成前后端对接，实现用户登录/注册最小功能闭环，并连接真实数据库
- 推进 Hadoop 环境熟悉与日志采集：Flume → HDFS 端到端打通与截图验证
- 启动 AI Agent/MCP 学习与集成方向的准备工作，整理术语与关系

## 任务分解（Owner）
- 接口规范与联调（沈永佳、邢远鑫）
  - 定义登录/注册接口请求/响应字段与错误码口径，完成最小闭环联调与截图
  - 前端封装 `{code,msg,data}`、统一 `Authorization` 与错误提示，补充关键用例
- 数据库配置与后端对接（邹佳轩、沈永佳）
  - 本地 PostgreSQL 初始化与 `users` 表结构准备；编写连接与初始化脚本
  - 对齐 `backend/.env` 连接信息，跑通后端登录/注册真实校验
- Flume 日志采集（李涛）
  - 部署与配置 Flume，完成到 HDFS 的采集链路打通（全量+实时），输出端到端截图
  - 形成采集方案与关键参数（Channel 容量、滚动策略、压缩）说明
- Hadoop 与自动化测试（王祖旺）
  - 熟悉 HDFS 高级功能与 MapReduce 编程；补充自动化测试脚本与数据管理规范
- Prompt/Agent/MCP 学习（全体）
  - 梳理术语与技术关系，形成学习笔记与后续集成方向草案

## 时间安排
- 周一：接口规范初稿、数据库初始化与 `users` 表结构准备
- 周二：MPC service 健康检查与基础调用核验，修正配置与文档
- 周三：登录/注册联调完成最小闭环；整理联调截图与用例
- 周四：Flume → HDFS 采集验证与截图；参数与策略说明草案
- 周五：成员各自产出文档与脚本归档；Prompt/Agent/MCP 学习笔记沉淀
- 周末：阶段复盘与周总结，形成下周计划

## 验收标准
- 登录/注册：真实数据库校验通过；接口返回规范一致；联调截图与用例齐备
- 数据库：`users` 表结构可用；连接验证通过；有初始化脚本与说明
- Flume 采集：链路打通；全量/实时采集验证截图与流程说明完整
- MPC service：健康检查与基础调用成功；配置说明与检查清单完成
- 学习笔记：Prompt/Agent/MCP 关系清晰，存档可复用

## 风险与缓解
- 认证与仓库推送凭据问题 → 先本地沉淀文档，凭据就绪后统一推送
- 环境差异与编码问题 → 统一英文路径与文件命名；`.gitignore` 忽略临时文件
- MPC 依赖与版本差异 → 列出依赖清单与 checklist，逐项核验修正
