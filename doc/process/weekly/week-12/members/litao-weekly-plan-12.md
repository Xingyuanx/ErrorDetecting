# 第十二周个人周计划
**核心目标**：基于FastAPI搭建稳定的后端服务，聚焦日志接收接口开发与Hadoop日志结构化处理，完成Flume推送日志的接收适配、preprocess_log正则解析函数编写、结构化数据校验与存储，实现日志从接收→解析→结构化存储的完整流程，为后续日志分析与查询奠定基础
**前置准备**：已搭建的FastAPI开发环境、Python re库（正则处理）、Flume推送日志测试工具（Postman/Flume本地测试环境）、Hadoop多组件日志样本（HDFS/YARN/MapReduce）、pytest（接口/函数测试）、MySQL/Redis环境（结构化日志存储）、正则调试工具（VS Code正则插件）、Flume HTTP Sink配置文档

## 周日：FastAPI服务架构完善与Flume日志接收适配
- 1. 项目架构优化：补充日志处理专属模块目录（log/（接收模块）、log_parser/（解析模块）、log_storage/（存储模块）），明确各模块职责与调用关系
- 2. Flume推送格式分析：研读Flume HTTP Sink配置文档，梳理Flume推送日志的请求特征（POST请求体格式、Content-Type类型、数据编码方式）
- 3. 基础日志接收接口开发：编写POST /api/log/receive接口，适配Flume推送的请求参数格式，实现原始日志数据的接收与初步校验
- 4. 连通性测试：使用Postman模拟Flume POST请求（携带原始Hadoop日志数据），验证接口响应状态、数据接收完整性

## 周一：Hadoop日志格式分析与正则表达式编写
- 1. 日志样本收集与分析：整理HDFS/YARN/MapReduce等组件的典型日志样本，标注时间戳、日志级别、组件名、日志内容的格式特征
- 2. 正则表达式编写：基于指定格式（(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (\w+) (\w+): (.*)）编写正则匹配表达式，明确分组对应字段（timestamp/log_level/component/content）
- 3. 正则调试与验证：针对不同日志样本（正常格式、含特殊字符、字段缺失）调试正则，验证匹配准确率，记录不匹配场景的特征
- 4. 基础匹配函数封装：编写正则匹配底层函数，添加匹配失败的异常捕获（返回明确错误标识），避免解析流程中断

## 周二：preprocess_log函数开发与日志结构化
- 1. 核心函数开发：编写preprocess_log函数，集成正则匹配逻辑，将原始日志字符串解析为结构化字典（含timestamp、log_level、component、content字段）
- 2. 异常处理完善：针对日志格式不匹配、字段提取失败等场景，设置合理默认值（如log_level默认UNKNOWN），并添加解析状态标识（success/fail）
- 3. 单元测试编写：构建多组测试用例（覆盖正常日志、异常格式日志、空日志），使用pytest验证函数解析结果的准确性
- 4. 性能优化：优化正则编译逻辑（提前编译正则表达式避免重复编译），测试大批量日志解析的耗时，确保处理效率满足需求

## 周三：日志接收接口集成preprocess_log与数据校验
- 1. 接口逻辑整合：在/api/log/receive接口中调用preprocess_log函数，实现“接收原始日志→结构化解析”的端到端流程
- 2. 结构化数据校验：使用Pydantic定义StructuredLog模型，添加字段校验规则（如timestamp格式为YYYY-MM-DD HH:MM:SS、log_level为枚举值）
- 3. 异常响应设计：开发解析失败/校验失败的分支逻辑，返回统一格式的错误响应（含code、msg、error_detail字段）
- 4. 端到端测试：通过Postman发送不同类型日志请求，验证接口解析结果、校验逻辑、异常响应的准确性

## 周四：结构化日志存储与缓存优化
- 1. 数据库表设计：在MySQL中创建hadoop_logs表（字段：id、timestamp、log_level、component、content、create_time），设置索引优化查询
- 2. 存储函数开发：编写save_structured_log_to_mysql函数，将解析后的结构化日志写入数据库，实现批量写入优化
- 3. Redis缓存配置：封装缓存函数，缓存热门组件（如NameNode）近1小时的ERROR级别日志数量，减少数据库查询压力
- 4. 存储可靠性保障：添加数据库连接失败、写入超时的异常捕获与重试机制，记录存储失败日志

## 周五：Flume实际联调与接口兼容性优化
- 1. Flume配置调整：配置Flume HTTP Sink（指定FastAPI接口地址、请求格式、批次大小），完成Flume与后端服务的连通配置
- 2. 联调测试：启动Flume推送真实Hadoop日志，验证接口接收、解析、存储的全流程完整性，排查格式、编码、批次处理的兼容性问题
- 3. 批量接收优化：修改接口支持批量日志接收（请求体为日志列表），调整解析与存储逻辑，提升Flume推送效率
- 4. 监控指标开发：在接口中添加接收量、解析成功率、存储成功率的统计逻辑，输出实时监控日志

## 周六：综合测试
- 1. 性能压测：模拟Flume高并发推送场景（1000+条/秒），测试接口吞吐量、解析性能、数据库写入稳定性，定位性能瓶颈并优化
- 2. 问题修复：针对测试中发现的正则漏判、缓存失效、批量写入异常等问题，完成代码修复与回归测试