# 基于 Hadoop 的故障检测与自动恢复项目 运维技术栈学习指南（重制版）

## 学习目标与范围
- 面向运维角色，围绕“日志采集 → 故障诊断 → 自动修复 → 部署与监控”全流程，构建可落地的技术栈与实践能力。
- 输出可执行的学习任务、验收标准与交付物清单，直接支撑项目核心任务（任务 1–10）。

---

## 技术栈分层与学习要点

### 1. 操作系统与基础设施（Linux/网络/脚本/SSH）
- 关键知识：Linux 用户与权限、系统服务、文件系统、网络（TCP/IP、端口）、防火墙、SSH 免密、NTP、JDK。
- 实践任务：
  - 完成 5 台以上节点的系统初始化（关闭防火墙、SSH 免密、JDK 安装与环境变量）。
  - 编写常用维护脚本（日志清理、进程检查、磁盘监控）。
- 验收标准：批量免密登录可用；基础脚本在所有节点成功执行并产生日志。
- 交付物：初始化记录与脚本集、节点清单与角色表。

### 2. Hadoop 集群运维（HDFS/YARN/MapReduce）
- 关键知识：NameNode/DataNode/ResourceManager/NodeManager 职责与拓扑；核心配置与启动/停止；WebUI 使用；常见故障定位。
- 实践任务：
  - 部署并验证 HDFS/YARN；通过 `jps` 与 WebUI 确认进程与状态。
  - 完成 NameNode 格式化与副本数设置；执行简单 MapReduce 示例并观察 YARN 任务状态。
- 验收标准：HDFS/YARN 正常运行；能稳定提交与完成一个 MR 任务；具备基础故障处理清单（DataNode 下线、端口占用）。
- 交付物：集群部署文档、核心配置备份、故障处理手册（基础版）。

### 3. 分布式存储与数据库（HDFS/MySQL/Redis）
- 关键知识：HDFS 权限与副本策略；MySQL 安装配置、备份与权限；Redis 缓存策略与安全。
- 实践任务：
  - 创建日志归档目录并设置权限与副本；
  - 部署 MySQL/Redis，完成备份计划与访问控制；设计故障记录与操作日志表结构。
- 验收标准：HDFS `fsck` 通过；MySQL 每日增量备份可恢复；Redis 缓存命中率达预期。
- 交付物：存储架构说明、备份脚本与恢复演练报告、表结构与权限清单。

### 4. 日志采集与传输（Flume/Kafka 选修）
- 关键知识：Flume Source/Channel/Sink 链路设计；批量与滚动策略；过滤与预处理；性能调优。
- 实践任务：
  - 在多节点部署 Flume Agent；配置 exec/hdfs Source 与 File/Memory Channel；统一 Sink 指向后端接口或 HDFS。
  - 压测与容错策略（批量大小、重试、失败队列）。
- 验收标准：多源日志稳定采集；在 2000 条/秒场景无明显积压与丢失；失败数据可追溯。
- 交付物：Flume 部署手册、标准化配置模板、压测与优化报告。

### 5. 后端服务与接口运维（FastAPI 运行/配置/日志）
- 关键知识：FastAPI 运行模式（uvicorn/gunicorn）；OpenAPI 文档；配置与环境变量；日志与异常处理；健康检查。
- 实践任务：
  - 部署后端服务（开发与容器模式）；实现 `/health` 与核心接口的探活与监控；统一错误响应。
  - 生成与维护 OpenAPI 文档；制定接口版本策略（如 `/v1`）。
- 验收标准：后端在目标环境稳定运行；开放文档与探活可用；发生异常时可快速定位。
- 交付物：运行与配置说明、日志策略与异常处理规范、OpenAPI 导出文件。

### 6. 自动化修复与脚本（Shell/SSH/风险控制）
- 关键知识：修复脚本库设计与参数化；风险分级（low/medium/high）；执行日志捕获与回滚策略；审批与确认流程。
- 实践任务：
  - 编写并验证常用脚本（重启 DataNode、清理临时文件、终止长时任务等）。
  - 建立执行权限与审批机制，记录执行日志并同步状态到后端/前端。
- 验收标准：低风险脚本自动执行稳定；中高风险脚本具备双重确认与回滚方案。
- 交付物：脚本库与操作规范、执行日志样例、风险与审批流程说明。

### 7. 容器化与编排（Docker/Compose/Kubernetes 本地）
- 关键知识：Dockerfile 最佳实践（分层/缓存/非 root/健康检查）；Compose 多服务编排；K8s 清单（Deployment/Service/ConfigMap/Probe/资源配额）。
- 实践任务：
  - 为后端生成 Dockerfile 与 `.dockerignore`；编写 `docker-compose.yml` 启停多服务；
  - 使用 kind/minikube 部署 K8s 清单，配置 Readiness/Liveness 与资源限额。
- 验收标准：镜像构建稳定、体积可控；Compose 一键启停；K8s 探针通过且资源受控。
- 交付物：容器化规范、Compose 与 K8s 清单、部署与联调指南。

### 8. 监控与告警（Prometheus/Grafana/EFK/DingTalk）
- 关键知识：指标采集与可视化；日志聚合与检索；告警规则与通知渠道；SLO/SLA 基础。
- 实践任务：
  - 搭建基础监控面板（采集量、成功率、延迟、故障状态）；配置告警阈值与通知（如机器人）。
  - 集成容器日志与应用日志，建立问题排查路径。
- 验收标准：核心指标可视化齐全；告警规则有效且无明显噪声；日志可检索定位问题。
- 交付物：监控面板截图、告警与日志方案、运维操作手册。

### 9. 测试与验收（Postman/脚本化测试/用例管理）
- 关键知识：接口测试与集合管理；场景化测试（采集—诊断—修复）；数据一致性与性能基线。
- 实践任务：
  - 配置环境与集合，覆盖核心路径；记录问题与修复；建立基本性能基线（TestDFSIO 等）。
- 验收标准：核心路径 100% 覆盖；问题闭环记录完整；性能指标达标（可复现）。
- 交付物：测试集合与报告、问题清单与对策记录、性能基线说明。

### 10. 评估与分析（SQL/Pandas/报表）
- 关键知识：指标口径（准确性/时效性/有效性）；数据抽取与统计；报表与迭代计划。
- 实践任务：
  - 从 MySQL 抽取诊断/修复数据，生成周报；分析异常案例并提出优化建议。
- 验收标准：三类核心指标可计算且趋势可视化；形成可执行迭代计划。
- 交付物：评估报表样例、分析脚本与指标字典。

---

## 分阶段学习路线（3 周，1.5 小时/天）
- 第 1 周（基础搭建）：Linux/网络脚本 → Hadoop/HDFS/YARN → 基础数据库（MySQL/Redis）
- 第 2 周（数据与服务）：Flume 部署与调优 → FastAPI 运行与探活 → 自动化修复脚本与风险控制
- 第 3 周（交付与保障）：Docker/Compose/K8s 本地编排 → 监控与告警 → 测试与评估报表

---

## 交付物与验收标准（汇总）
- 文档与规范：部署与配置说明、容器化与监控规范、修复脚本操作规范。
- 配置与脚本：Hadoop/Flume/后端/Compose/K8s 清单与脚本库。
- 报告与面板：压测与稳定性报告、测试用例与问题清单、监控面板与告警规则、评估周报。
- 验收：
  - 可运行：采集—诊断—修复—监控全链路最小闭环可演示。
  - 可复现：部署与启停一键化；脚本与配置版本化管理齐备。
  - 可观测：探活、指标与日志可用，告警有效。

---

## 推荐学习资源
- Hadoop 官方文档：https://hadoop.apache.org/
- Flume 官方文档：https://flume.apache.org/
- FastAPI 文档：https://fastapi.tiangolo.com/
- Docker 文档：https://docs.docker.com/ ; Compose：https://docs.docker.com/compose/
- Kubernetes 文档：https://kubernetes.io/docs/home/ ; kind：https://kind.sigs.k8s.io/ ; Minikube：https://minikube.sigs.k8s.io/
- Prometheus：https://prometheus.io/ ; Grafana：https://grafana.com/
- MySQL：https://dev.mysql.com/doc/ ; Redis：https://redis.io/docs/
- Postman：https://learning.postman.com/
- Python Pandas：https://pandas.pydata.org/

---

## 与项目核心任务的映射
- 任务 1–2：对应分层 1/2/3（集群与存储）
- 任务 3–5：对应分层 4/5（采集与接口）
- 任务 6–7：对应分层 6（修复与风险）
- 任务 8–10：对应分层 7/8/9/10（部署、监控、测试、评估）

> 说明：本学习指南以运维落地为导向，组织为“分层要点+实践任务+验收与交付”，可直接用于周计划与周总结的生成与评审。

---

## 学习内容详解与示例

### 1. 操作系统与基础设施详解
- 知识清单：用户/组与权限、进程与服务、网络端口与防火墙、时间同步、SSH 免密、环境变量与 JDK。
- 关键命令：
  - 用户与权限：`useradd`、`passwd`、`usermod -aG`、`chmod`、`chown`、`sudo visudo`
  - 服务管理：`systemctl enable|start|status`、`journalctl -u <service>`
  - 端口与网络：`ss -lntp`、`ip a`、`ping`、`traceroute`、`curl -I`
  - 防火墙：`ufw status`、`ufw allow 8020/tcp` 或 `firewall-cmd --add-port=8020/tcp --permanent`
  - 时间：`timedatectl`、`chronyc sources` 或 `ntpdate`
  - SSH 免密：`ssh-keygen -t ed25519`、`ssh-copy-id user@host`、`~/.ssh/config`
  - JDK：`java -version`、在 `/etc/profile.d/java.sh` 配置 `JAVA_HOME`、`PATH`
- 示例脚本：
  - 健康检查 `healthcheck.sh`：采集 CPU/内存/磁盘/端口占用，输出到 `/var/log/ops/health-$(hostname).log`
  - 日志清理 `cleanup_logs.sh`：按规则清理 `/var/log/*` 与项目日志，保留最近 N 天
- 验收与交付：多节点免密可用；统一初始化脚本在所有节点执行成功并产生日志与报告。

### 2. Hadoop 集群运维详解
- 核心配置文件：`core-site.xml`、`hdfs-site.xml`、`yarn-site.xml`、`mapred-site.xml`
- 常用属性示例：
  - `core-site.xml`：`fs.defaultFS`、`io.file.buffer.size`
  - `hdfs-site.xml`：`dfs.replication`、`dfs.namenode.name.dir`、`dfs.datanode.data.dir`
  - `yarn-site.xml`：`yarn.nodemanager.resource.memory-mb`、`yarn.scheduler.maximum-allocation-mb`
  - `mapred-site.xml`：`mapreduce.framework.name=yarn`
- 操作步骤：
  - 格式化 NameNode：`hdfs namenode -format`
  - 启停：`start-dfs.sh`、`start-yarn.sh`、`mr-jobhistory-daemon.sh start historyserver`
  - 校验：`jps`、WebUI（`50070` `8088`）
  - HDFS 操作：`hdfs dfs -mkdir -p /apps/logs`、`hdfs dfs -put ./logs/*.log /apps/logs/`
  - MR 示例：`yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples.jar pi 3 1000`
- 故障排查清单：端口占用、DataNode 下线、磁盘挂载错误、权限不足，使用 `jps`/`netstat`/`tail -f` 对应日志定位。

### 3. 分布式存储与数据库详解
- HDFS：权限与副本策略，使用 `hdfs dfs -chmod`、`-chown`、`-setrep`；一致性检查 `hdfs fsck / -files -blocks -locations`
- MySQL：
  - 安装与配置：`my.cnf` 基本参数（`bind-address`、`max_connections`、`slow_query_log`）
  - 备份与恢复：`mysqldump -u root -p db > backup.sql`；`mysql -u root -p db < backup.sql`
  - 账户与权限：`CREATE USER`、`GRANT SELECT,INSERT,UPDATE ON db.* TO 'ops'@'%';`
- Redis：
  - 配置：`redis.conf` 中设置 `requirepass`、`maxmemory`、`maxmemory-policy allkeys-lru`
  - 监控：`INFO`、`SLOWLOG`、`MONITOR`，键过期与命中率分析
- 业务表结构示例（故障记录与操作日志）：
  - `incidents(id, type, node, started_at, ended_at, status, severity, summary)`
  - `ops_actions(id, incident_id, operator, action, risk_level, executed_at, result, detail)`

### 4. 日志采集与传输详解（Flume）
- 典型拓扑：多 Source（exec/taildir）→ Memory/File Channel → Sink（HDFS/HTTP）
- 配置示例（简化）：
  ```properties
  a1.sources = s1
  a1.channels = c1
  a1.sinks = k1
  a1.sources.s1.type = exec
  a1.sources.s1.command = tail -F /var/log/app/app.log
  a1.channels.c1.type = memory
  a1.channels.c1.capacity = 10000
  a1.channels.c1.transactionCapacity = 1000
  a1.sinks.k1.type = hdfs
  a1.sinks.k1.hdfs.path = hdfs://nn:8020/apps/logs/%Y/%m/%d/
  a1.sinks.k1.hdfs.fileType = DataStream
  a1.sinks.k1.hdfs.rollInterval = 60
  a1.sinks.k1.channel = c1
  ```
- 启动与调试：`flume-ng agent -n a1 -f conf/log2hdfs.conf -Dflume.root.logger=INFO,console`
- 性能与容错：调整 `batchSize`、`channelCapacity`；失败队列与重试；监控通道积压。

### 5. 后端服务与接口运维详解（FastAPI）
- 运行模式：开发 `uvicorn main:app --reload`；生产 `gunicorn -k uvicorn.workers.UvicornWorker -w 2 main:app`
- 健康检查与日志：
  - `/health` 返回依赖组件状态（DB、HDFS、Flume）与版本
  - 统一日志格式（JSON），接入标准 `logging` 配置与日志轮转
- 配置与环境变量：使用 `.env` 或 `pydantic BaseSettings` 管理敏感配置；区分 dev/prod
- 错误处理：统一 `HTTPException`、全局异常中间件，输出可追踪 `trace_id`
- OpenAPI：`/docs` 与 `/openapi.json` 可用；接口版本前缀 `/v1`

### 6. 自动化修复与脚本详解
- 设计原则：参数化、幂等、可审计、可回滚；风险分级与审批流程
- 示例：
  - 重启 DataNode：`ssh nodeX 'systemctl restart hadoop-hdfs-datanode'`
  - 清理临时：`find /data/tmp -type f -mtime +3 -delete`
  - 终止长时任务：`yarn application -kill <appId>`
- 执行日志：所有脚本输出到 `ops-actions.log`，包含时间、节点、操作者、结果、细节
- 防误触：`--dry-run` 与二次确认（例如要求 `--yes` 两次）

### 7. 容器化与编排详解
- Dockerfile 要点：使用 `python:3.11-slim`、非 root 用户、`HEALTHCHECK`、分层与缓存、`PIP_NO_CACHE_DIR`
- `.dockerignore`：忽略虚拟环境、日志、临时与测试数据
- Compose 示例：后端 + MySQL + Redis + Flume 可一键编排；定义健康检查与依赖顺序
- K8s 清单关键项：`Deployment`（副本数、资源配额）、`Service`、`ConfigMap`、`Readiness/Liveness` 探针

### 8. 监控与告警详解
- 指标：采集量、成功率、延迟、错误率、队列积压、容器资源；SLO/SLA 定义与阈值
- Prometheus：抓取后端与导出器（node_exporter、blackbox）；告警规则示例在 `rules.yml`
- Grafana：仪表盘分层（资源/应用/业务）；模板变量与告警联动
- 日志聚合：EFK/ELK；建立索引与查询语句（如按 `trace_id` 与 `severity` 检索）
- 通知：集成机器人（如钉钉 webhook），告警抑制与静默策略

### 9. 测试与验收详解
- 接口测试：Postman/Newman 集合与环境变量；覆盖核心链路（采集→诊断→修复）
- 脚本化测试：利用 shell/python 进行冒烟与回归；对关键脚本做幂等校验
- 性能基线：HDFS `TestDFSIO`、Flume 压测；记录 QPS、延迟、失败率
- 测试产物：报告、问题清单、变更记录与复现脚本

### 10. 评估与分析详解
- 指标口径：准确性（错误识别率）、时效性（平均修复时长）、有效性（闭环率）
- 数据抽取：从 MySQL 抽取 `incidents` 与 `ops_actions`，用 Pandas 统计与可视化
- 周报模板：结论（达成/风险）、指标趋势图、问题与对策、下周计划

---

## 每日任务清单（示例，3 周×1.5 小时/天）
- 第 1 周：
  - Day 1：系统初始化与 SSH 免密；编写健康检查脚本
  - Day 2：防火墙与端口策略；JDK 与环境变量
  - Day 3：部署 HDFS；格式化 NN 与基础操作
  - Day 4：部署 YARN；提交 MR 示例并观察任务
  - Day 5：HDFS 权限与副本；`fsck` 与故障演练
  - Day 6：安装 MySQL/Redis；账号与备份策略
  - Day 7：周总结与复盘；完善部署与脚本
- 第 2 周：
  - Day 8：部署 Flume；单源到 HDFS
  - Day 9：多源汇聚与参数调优；压测与容错
  - Day 10：部署后端；`/health` 与日志规范
  - Day 11：OpenAPI 与版本管理；统一错误响应
  - Day 12：自动化修复脚本设计与低风险脚本验证
  - Day 13：审批与回滚机制；执行日志打通
  - Day 14：周总结与复盘；联调采集—接口—修复
- 第 3 周：
  - Day 15：Dockerfile 与镜像构建；`.dockerignore`
  - Day 16：Compose 多服务编排；一键启停
  - Day 17：K8s 本地部署；Readiness/Liveness 探针
  - Day 18：Prometheus/Grafana 指标与告警规则
  - Day 19：日志聚合与检索；排查路径固化
  - Day 20：Postman 集合与性能基线；问题闭环
  - Day 21：评估报表与周报输出；整体复盘

---

## 练习与验收样例（可直接使用）
- 练习：将 `app.log` 通过 Flume 写入 HDFS，再由后端接口读取并统计错误数，输出到 MySQL `incidents` 表。
- 验收：提交 MR 示例与接口集合；展示监控面板与告警；演示一次故障发现→自动修复→记录入库→报表输出的闭环。
