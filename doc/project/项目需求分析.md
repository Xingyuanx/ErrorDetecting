# 基于 Hadoop 的故障检测与智能诊断项目 - 需求分析

## 1. 业务流程分析

### 1.1 指标采集流程 (Metrics Collection)
1. **调度**: `metrics_worker.py` 周期性触发采集任务。
2. **连接**: 通过 `ssh_utils.py` 获取对应节点的 SSH 会话（支持 SOCKS5 代理）。
3. **执行**: 远程执行系统命令（如 `top`, `free`）获取 CPU 和内存使用率。
4. **持久化**: 数据经过处理后存入 `node_metrics` 和 `cluster_metrics` 表，并支持动态 Schema 维护。

### 1.2 日志采集与读取流程 (Log Collection)
1. **实时读取**: 用户通过 `/hadoop/logs/{node}/{type}` 接口请求日志，系统通过 SSH 实时 `cat` 或 `tail` 远程文件。
2. **自动采集**: `log_collector.py` 维护多个任务线程，利用 `tail -F` 模式监控远程 Hadoop 日志文件的增量更新。
3. **入库**: 采集到的原始日志流经解析后，批量存入 `hadoop_logs` 表，供后续 AI 诊断和历史查询使用。

### 1.3 AI 智能诊断流程 (AI Diagnosis)
1. **触发**: 用户在 UI 或通过 API 发起对话，描述故障现象。
2. **编排**: `diagnosis_agent.py` 接收请求，利用 OpenAI Tool Calling 协议决定下一步行动。
3. **工具执行**: 智能体根据需要调用后端定义的工具，如：
    - `get_cluster_info`: 获取集群节点列表。
    - `read_node_logs`: 读取特定节点的实时日志。
    - `execute_remote_command`: 在节点上执行诊断指令。
4. **总结**: 智能体整合工具返回的上下文，生成结构化的根因分析报告及修复建议。

## 2. 功能需求分解

### 2.1 基础设施与管理 (F-01)
- **集群注册**: 记录 NameNode/ResourceManager IP 及 SSH 凭据，支持连通性校验。
- **节点自动发现**: 获取集群内的所有主机信息及其角色。

### 2.2 监控与告警 (F-02)
- **实时看板**: 展示集群整体及单个节点的 CPU/内存 负载曲线。
- **状态监控**: 自动识别节点在线/离线状态。

### 2.3 日志管理 (F-03)
- **多节点检索**: 支持按集群、节点、日志类型（NameNode/DataNode/Audit 等）进行分页查询。
- **文件管理**: 自动探测远程 Hadoop 日志目录下的文件列表。

### 2.4 智能运维 (F-04)
- **AI 对话**: 提供 SSE 流式对话接口，支持长上下文故障分析。
- **任务审计**: 记录所有通过平台执行的远程命令及其输出结果 (Exec Logs)。

## 3. 非功能需求

### 3.1 性能要求
- **并发采集**: 日志采集器需支持至少 50 个节点并发 tail 而不阻塞主服务。
- **查询响应**: 数据库百万级日志量下，常用过滤查询响应时间应在 1s 以内。

### 3.2 安全性要求
- **凭据加密**: 数据库存储的 SSH 密码应加密处理。
- **权限隔离**: 不同角色的用户仅能访问其所属集群的数据。

### 3.3 可扩展性
- **工具扩展**: AI 智能体应能通过简单的接口定义轻松接入新的运维工具。
- **Schema 动态性**: 指标表应能根据新采集的维度自动扩展列。

## 4. 接口协议约定
- **RESTful API**: 遵循 `/api/v1` 前缀。
- **SSE (Server-Sent Events)**: AI 对话采用流式输出，确保前端实时展示诊断进度。
- **WebSocket (可选)**: 用于实时指标推送。
