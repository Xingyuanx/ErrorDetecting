# 前端聊天联调指南

本指南用于对接后端聊天接口，支持多轮对话、上下文感知（MCP）及工具调用（Function Calling）。

## 1. 基础信息

- **后端地址**：`http://localhost:8000` (开发环境)
- **API 前缀**：`/api/v1`
- **鉴权方式**：`Authorization: Bearer <token>`
- **相关文件**：
  - 路由实现：`backend/app/routers/ai.py`
  - 数据模型：`backend/app/models/chat.py`

## 2. 核心流程

1.  **初始化**：用户进入诊断页面，前端调用 `GET /ai/history` 获取该会话的历史记录。
2.  **发送消息**：用户输入消息，前端调用 `POST /ai/chat` 发送消息 + 当前上下文（节点/智能体信息）。
3.  **接收回复**：后端自动处理工具调用和多轮对话逻辑，返回最终回复。

---

## 3. 接口契约

### 3.1 获取会话历史

用于页面加载时恢复对话记录。

- **URL**: `GET /api/v1/ai/history`
- **Query Params**:
  - `sessionId` (string, required): 会话唯一标识（建议前端生成 UUID 或使用固定前缀如 `diagnosis-{nodeId}`）
- **Response**:
  ```json
  {
    "messages": [
      {
        "role": "user",
        "content": "请检查 hadoop-node1 的 CPU 使用率"
      },
      {
        "role": "assistant",
        "content": "CPU 使用率正常..."
      }
    ]
  }
  ```

### 3.2 发送消息（智能体对话）

- **URL**: `POST /api/v1/ai/chat`
- **Content-Type**: `application/json`
- **Body**:
  ```json
  {
    "sessionId": "diagnosis-default-001",
    "message": "帮我分析一下当前的错误日志",
    "context": {
      "node": "hadoop-node1",
      "agent": "诊断智能体",
      "model": "DeepSeek-R1"
    }
  }
  ```
  - `sessionId`: 必填，保持与 `get_history` 一致。
  - `message`: 必填，用户输入。
  - `context`: 选填，上下文信息。
    - `node`: 当前选中的节点主机名（后端会自动注入 System Prompt）。
    - `agent`: 当前智能体名称。
- **Response**:
  ```json
  {
    "reply": "根据日志分析，DataNode 端口冲突...",
    "reasoning": "查看了日志文件 /var/log/hadoop/... 发现 BindException..."
  }
  ```
  - `reply`: 最终展示给用户的回复文本。
  - `reasoning`: (可选) 模型推理过程，前端可选择性展示（如折叠面板）。

---

## 4. 前端调用示例 (TypeScript/Fetch)

```typescript
const API_BASE = "http://localhost:8000/api/v1";

// 1. 获取 Token (假设已登录)
const getToken = () => localStorage.getItem("cm_token");

// 2. 获取历史记录
async function getChatHistory(sessionId: string) {
  const resp = await fetch(`${API_BASE}/ai/history?sessionId=${sessionId}`, {
    headers: {
      "Authorization": `Bearer ${getToken()}`
    }
  });
  if (!resp.ok) throw new Error("Failed to fetch history");
  return await resp.json();
}

// 3. 发送消息
async function sendChatMessage(sessionId: string, message: string, context: any) {
  const resp = await fetch(`${API_BASE}/ai/chat`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${getToken()}`
    },
    body: JSON.stringify({
      sessionId,
      message,
      context
    })
  });
  
  if (!resp.ok) {
     const err = await resp.json();
     throw new Error(err.detail || "Chat failed");
  }
  
  return await resp.json();
}
```

## 5. 常见问题 (FAQ)

**Q: `sessionId` 应该怎么生成？**
A: 建议根据业务场景生成。如果是全局诊断，可以使用固定的 `diagnosis-global`；如果是针对特定节点的诊断，可以使用 `diagnosis-{nodeId}`。保持 `sessionId` 不变可以延续上下文。

**Q: 为什么有时候响应很慢？**
A: 后端模型（DeepSeek-R1）可能在进行联网搜索或长链推理。后端已设置 120s 超时，前端请求超时时间建议设置在 60s 以上。

**Q: `reasoning` 字段是做什么的？**
A: 这是推理模型的思维链（Chain of Thought）。前端可以将其放在一个可折叠的详情块中，增加 AI 的透明度，但不建议作为主要内容直接展示。

**Q: 遇到 401 错误怎么办？**
A: Token 过期或未登录。请跳转至登录页重新获取 Token。
