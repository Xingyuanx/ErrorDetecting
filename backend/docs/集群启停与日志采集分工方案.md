# 集群管理与日志收集开发协作方案

为了确保两人协作时代码不产生冲突，采用**关注点分离（Separation of Concerns）**原则，将运维操作与数据采集完全解耦。

## 1. 分工概览

| 功能模块 | 核心职责 | 涉及层级 | 推荐开发者 |
| :--- | :--- | :--- | :--- |
| **集群启停 (Ops)** | 负责执行远程 SSH 命令（如 `start-all.sh`），处理操作状态反馈。 | Router: `ops.py`<br>Service: `cluster_ops_service.py` | A 同学 |
| **日志收集 (Logs)** | 负责从远程节点拉取/解析日志文件，持久化到数据库或提供流式读取。 | Router: `hadoop_logs.py`<br>Service: `log_manager_service.py` | B 同学 |

## 2. 详细路径与接口设计

### A 同学：集群运维 (Ops)
- **路由文件**: `backend/app/routers/ops.py`
- **服务文件**: `backend/app/services/cluster_ops_service.py`
- **主要接口**:
    - `POST /api/v1/ops/clusters/{cluster_uuid}/start`: 启动集群
    - `POST /api/v1/ops/clusters/{cluster_uuid}/stop`: 停止集群
- **核心逻辑**:
    - 从数据库读取集群 SSH 信息。
    - 使用 `ssh_probe.py` 执行启动/停止脚本。
    - 更新 `clusters` 表的 `health_status` 字段。

### B 同学：日志管理 (Logs)
- **路由文件**: `backend/app/routers/hadoop_logs.py`
- **服务文件**: `backend/app/services/log_manager_service.py`
- **主要接口**:
    - `POST /api/v1/hadoop-logs/collect`: 触发特定节点的日志收集
    - `GET /api/v1/hadoop-logs/{cluster_uuid}/status`: 查看收集任务状态
- **核心逻辑**:
    - 定位远程节点日志路径（如 `/usr/local/hadoop/logs`）。
    - 异步拉取日志内容并存入 `hadoop_logs` 表。

## 3. 协作规范

1. **Schema 共享**: 两人应先在 `backend/app/schemas.py` 中定义好各自的请求/响应模型。
2. **工具类复用**: 统一使用 `backend/app/ssh_utils.py` 进行 SSH 连接管理，严禁各自实现底层连接逻辑。
3. **数据库操作**:
    - 运维模块主要**读取**集群配置并**更新**状态。
    - 日志模块主要**写入**日志记录，不应修改集群核心配置。
4. **异常处理**: 统一返回 `HTTPException(status_code=500, detail="server_error")` 或自定义错误码。
